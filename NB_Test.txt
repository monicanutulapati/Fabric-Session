from pyspark.sql.functions import *
from pyspark.sql.types import *

# ----------------------------------------------------------------------
# 1. READ SILVER PARQUET FILES
# ----------------------------------------------------------------------

silver_path = "/lakehouse/default/Files/Silver/"

df_customers = (
    spark.read.format("parquet")
    .load(f"{silver_path}/Customers_Silver.parquet")
)

df_products = (
    spark.read.format("parquet")
    .load(f"{silver_path}/Products_Silver.parquet")
)

df_sales = (
    spark.read.format("parquet")
    .load(f"{silver_path}/Sales_Silver.parquet")
)

print("Silver files loaded successfully!")

# ----------------------------------------------------------------------
# 2. SAFETY CLEANING (optional but recommended)
# ----------------------------------------------------------------------

df_customers = df_customers.dropDuplicates()
df_products = df_products.dropDuplicates()
df_sales    = df_sales.dropDuplicates()

df_sales = df_sales.withColumn("Date", to_date(col("Date")))

# ----------------------------------------------------------------------
# 3. BUILD GOLD FACT TABLE
# ----------------------------------------------------------------------

df_gold = (
    df_sales
    .join(df_customers, "CustomerID", "left")
    .join(df_products, "ProductID", "left")
)

# Add revenue
df_gold = df_gold.withColumn("revenue", col("Quantity") * col("Price"))

print("Gold fact table created!")

# ----------------------------------------------------------------------
# 4. WRITE GOLD AS DELTA TABLES (Lakehouse Managed Tables)
# ----------------------------------------------------------------------

df_customers.write.mode("overwrite").saveAsTable("customers_clean")
df_products.write.mode("overwrite").saveAsTable("products_clean")
df_gold.write.mode("overwrite").saveAsTable("sales_enriched")

print("Delta tables written successfully!")

# ----------------------------------------------------------------------
# 5. (Optional) Register SQL External References
# ----------------------------------------------------------------------

spark.sql("""
CREATE TABLE IF NOT EXISTS customers_clean
USING DELTA
LOCATION '/lakehouse/default/tables/customers_clean'
""")

spark.sql("""
CREATE TABLE IF NOT EXISTS products_clean
USING DELTA
LOCATION '/lakehouse/default/tables/products_clean'
""")

spark.sql("""
CREATE TABLE IF NOT EXISTS sales_enriched
USING DELTA
LOCATION '/lakehouse/default/tables/sales_enriched'
""")

print("SQL tables registered!")